{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "\n",
    "path_prefix = \"../\"\n",
    "sys.path.insert(0, os.path.abspath(path_prefix))\n",
    "\n",
    "import config.path_config as env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define required Classes and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_processed_data(labels):\n",
    "    \n",
    "    path_empty = path_prefix + env.PATH_DATA_PROCESSED + env.PATH_DATA_COMBINED + \"empty\"\n",
    "    path_occupied = path_prefix + env.PATH_DATA_PROCESSED + env.PATH_DATA_COMBINED + \"occupied\"\n",
    "    \n",
    "    if not os.path.exists(path_empty):\n",
    "        os.makedirs(path_empty)\n",
    "        \n",
    "    if not os.path.exists(path_occupied):\n",
    "        os.makedirs(path_occupied)\n",
    "    \n",
    "    for index, row in labels.iterrows():\n",
    "        image_path = row['ImagePath']\n",
    "        image_label = row['ImageLabel']\n",
    "        \n",
    "        if row[\"ImageSource\"] == 'CNRPark':\n",
    "            image_path = path_prefix + env.PATH_DATA_RAW + env.PATH_DATA_CNRPARK + image_path\n",
    "            image_name = image_path.split('/')[-1]\n",
    "        elif row['ImageSource'] == 'CNR-EXT':\n",
    "            image_path = path_prefix + env.PATH_DATA_RAW + env.PATH_DATA_CNREXT + image_path\n",
    "            image_name = image_path.split('/')[-1]\n",
    "        else:\n",
    "            image_path = path_prefix + env.PATH_DATA_RAW + env.PATH_DATA_PKLOT + image_path\n",
    "            image_name = image_path.split('/')[-1]\n",
    "\n",
    "        if os.path.exists(image_path):\n",
    "            if image_label == 0:\n",
    "                shutil.move(image_path, path_empty)\n",
    "            else:\n",
    "                shutil.move(image_path, path_occupied)\n",
    "\n",
    "            print(\"File Moved Successfully: \" + image_name)\n",
    "        else:\n",
    "            print(\"File Not Found: %s\" % image_name)\n",
    "        pass\n",
    "    \n",
    "def remove_extra_images(min_width, min_height):\n",
    "    \n",
    "    data_combined_path = path_prefix + env.PATH_DATA_PROCESSED + env.PATH_DATA_COMBINED\n",
    "    \n",
    "    for label_folder in os.listdir(data_combined_path):\n",
    "        for data_type in os.listdir(data_combined_path + label_folder + '/'):\n",
    "            temp_path = data_combined_path + label_folder + '/' + data_type\n",
    "            \n",
    "            im_ = cv2.imread(temp_path)\n",
    "            im_ = np.array(im_)\n",
    "            \n",
    "            if im_.shape[0] < min_width or im_.shape[1] < min_height:\n",
    "                os.remove(temp_path)\n",
    "                print('Removed ' + temp_path)\n",
    "            pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import CNRPark+EXT dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation available here: http://cnrpark.it/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNRPark - http://cnrpark.it/dataset/CNRPark-Patches-150x150.zip\n",
    "#### CNR-EXT - http://cnrpark.it/dataset/CNR-EXT-Patches-150x150.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnr_dataset_url = \"http://cnrpark.it/dataset/\"\n",
    "cnr_park_dataset_name = \"CNRPark-Patches-150x150.zip\"\n",
    "cnr_ext_dataset_name = \"CNR-EXT-Patches-150x150.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Download CNRPark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.exists(path_prefix + env.PATH_DATA_RAW + cnr_park_dataset_name):\n",
    "    cnr_park_dataset_zip = zipfile.ZipFile(path_prefix + env.PATH_DATA_RAW + cnr_park_dataset_name, 'r')\n",
    "else:\n",
    "    r = requests.get(cnr_dataset_url + cnr_park_dataset_name)\n",
    "    with open(path_prefix + env.PATH_DATA_RAW + cnr_park_dataset_name, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "    cnr_park_dataset_zip = zipfile.ZipFile(io.BytesIO(r.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Extract the zip file for CNRPark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cnr_park_dataset_zip.extractall(path_prefix + env.PATH_DATA_RAW + \"CNRPark-Patches-150x150\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Download CNR-Ext dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.exists(path_prefix + env.PATH_DATA_RAW + cnr_ext_dataset_name):\n",
    "    cnr_ext_dataset_zip = zipfile.ZipFile(path_prefix + env.PATH_DATA_RAW + cnr_ext_dataset_name, 'r')\n",
    "else:\n",
    "    r = requests.get(cnr_dataset_url + cnr_ext_dataset_name)\n",
    "    with open(path_prefix + env.PATH_DATA_RAW + cnr_ext_dataset_name, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "    cnr_ext_dataset_zip = zipfile.ZipFile(io.BytesIO(r.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Extract the zip file for CNR-Ext dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cnr_ext_dataset_zip.extractall(path_prefix + env.PATH_DATA_RAW + \"CNR-EXT-Patches-150x150\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Import PKLot dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation available here: https://web.inf.ufpr.br/vri/databases/parking-lot-database/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually download and extract the PKLot.tar.gz file and place the content inside data/raw/PKLot/ directory \n",
    "#### PKLot.tar.gz: http://www.inf.ufpr.br/vri/databases/PKLot.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pklot_path = path_prefix + env.PATH_DATA_RAW + env.PATH_DATA_PKLOT\n",
    "pklot_labels_path = path_prefix + env.PATH_DATA_RAW + env.PATH_LABELS_PKLOT\n",
    "\n",
    "if not os.path.exists(pklot_path):\n",
    "    print('PKLot Directory does not exists')\n",
    "else:\n",
    "    labels_array = []\n",
    "\n",
    "    for cameraFolder in os.listdir(pklot_path):\n",
    "        cameraFolderPath = pklot_path + cameraFolder + '/'\n",
    "        print('--Inside:', cameraFolder)\n",
    "\n",
    "        for seasonFolder in os.listdir(cameraFolderPath):\n",
    "            seasonFolderPath = cameraFolderPath + seasonFolder + '/'\n",
    "            print('----Inside: ', cameraFolder + '/' + seasonFolder)\n",
    "\n",
    "            for dateFolder in os.listdir(seasonFolderPath):\n",
    "                dateFolderPath = seasonFolderPath + dateFolder + '/'\n",
    "                print('--------Inside: ', cameraFolder + '/' + seasonFolder + '/' + dateFolder)\n",
    "\n",
    "                for labelFolder in os.listdir(dateFolderPath):\n",
    "                    labelFolderPath = dateFolderPath + labelFolder + '/'\n",
    "                    print('----------------Inside: ',\n",
    "                          cameraFolder + '/' + seasonFolder + '/' + dateFolder + '/' + labelFolder)\n",
    "\n",
    "                    for image in os.listdir(labelFolderPath):\n",
    "                        imagePath = cameraFolder + '/' + seasonFolder + '/' + dateFolder + '/' + labelFolder + '/' + image\n",
    "                        # imagePath = os.path.relpath(imagePath, env.PATH_DATA_PKLOT)\n",
    "                        print('--------------------Image: ' + image)\n",
    "                        if labelFolder == 'Empty':\n",
    "                            labels_array.append([imagePath, 0])\n",
    "                        if labelFolder == 'Occupied':\n",
    "                            labels_array.append([imagePath, 1])\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "    labels = pd.DataFrame(data=labels_array, columns=['ImagePath', 'ImageLabel'])\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(pklot_labels_path):\n",
    "        os.makedirs(pklot_labels_path)\n",
    "    \n",
    "    pklot_labels = labels.sample(frac=1)\n",
    "    \n",
    "    print(pklot_labels.shape)\n",
    "    \n",
    "    pklot_labels.to_csv(pklot_labels_path + 'all.txt', sep=' ', index=None)\n",
    "    \n",
    "    \n",
    "    # labels_train = labels.sample(frac=0.70)\n",
    "    # labels.drop(index=labels_train.index, inplace=True)\n",
    "\n",
    "    # labels_test = labels.sample(frac=0.15)\n",
    "    # labels.drop(index=labels_test.index, inplace=True)\n",
    "\n",
    "    # labels_val = labels.sample(frac=0.15)\n",
    "    # labels.drop(index=labels_val.index, inplace=True)\n",
    "\n",
    "    # labels_train.to_csv(pklot_labels_path + 'train.txt', sep=' ', index=None)\n",
    "    # labels_test.to_csv(pklot_labels_path + 'test.txt', sep=' ', index=None)\n",
    "    # labels_val.to_csv(pklot_labels_path + 'val.txt', sep=' ', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Merge CNR and PKLot data and move to data/processed/ directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Move CNRPark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cnr_park_labels = pd.DataFrame(columns=['ImagePath', 'ImageLabel', 'ImageSource'])\n",
    "\n",
    "for category_folder in os.listdir(path_prefix + env.PATH_DATA_RAW + env.PATH_DATA_CNRPARK):\n",
    "    image_source = 'CNRPark'\n",
    "    \n",
    "    print('--Inside: ', category_folder)\n",
    "    label_folder_path = path_prefix + env.PATH_DATA_RAW + env.PATH_DATA_CNRPARK + category_folder + \"/\"\n",
    "    \n",
    "    for label_folder in os.listdir(label_folder_path):\n",
    "        print('----Inside: ' + category_folder + \"/\" + label_folder)\n",
    "        file_folder_path = label_folder_path + label_folder + \"/\"\n",
    "        \n",
    "        for file in os.listdir(file_folder_path):\n",
    "            print('--------Inside: ' + file)\n",
    "            image_path = category_folder + \"/\" + label_folder + \"/\" + file\n",
    "            \n",
    "            image_label = 0\n",
    "            if label_folder == 'busy':\n",
    "                image_label = 1\n",
    "            elif label_folder == 'free':\n",
    "                image_label = 0\n",
    "                \n",
    "            \n",
    "            cnr_park_labels = cnr_park_labels.append({\"ImagePath\": image_path, \n",
    "                                                      \"ImageLabel\": image_label, \n",
    "                                                      \"ImageSource\": image_source}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnr_park_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnr_park_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "generate_processed_data(cnr_park_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Move CNR-EXT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.exists(path_prefix + env.PATH_DATA_RAW + env.PATH_LABELS_CNREXT + 'all.txt'):\n",
    "    print(\"File Found: %s\" % env.PATH_LABELS_CNREXT + 'all.txt')\n",
    "    cnr_ext_labels = pd.read_csv(path_prefix + env.PATH_DATA_RAW + env.PATH_LABELS_CNREXT + 'all.txt', delimiter=' ', header=None)\n",
    "    cnr_ext_labels['ImageSource'] = 'CNR-EXT'\n",
    "    cnr_ext_labels.columns = ['ImagePath', 'ImageLabel', 'ImageSource']\n",
    "else:\n",
    "    print(\"File Not Found: %\" % env.PATH_LABELS_CNREXT + 'all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnr_ext_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnr_ext_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generate_processed_data(cnr_ext_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Move PKLot dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pklot_labels = pd.read_csv(pklot_labels_path + 'all.txt', delimiter = ' ', header = 0)\n",
    "pklot_labels['ImageSource'] = 'Pklot'\n",
    "pklot_labels.columns = ['ImagePath', 'ImageLabel', 'ImageSource']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pklot_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pklot_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generate_processed_data(pklot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Remove Small/Extra Images from processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "remove_extra_images(min_width = 100, min_height = 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehicle-detection-dl-virtenv",
   "language": "python",
   "name": "vehicle-detection-dl-virtenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
